{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\tfilename = ../data/w-vs-qcd/anti-kt/antikt-test.pickle-py27-kt\n",
      "\tX size = 20000\n",
      "\ty size = 20000\n",
      "Preprocessing...\n",
      "\tX size = 7690\n",
      "\ty size = 7690\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from recnn.preprocessing import extract, permute_by_pt\n",
    "\n",
    "def load_test(filename):\n",
    "    # Make training data\n",
    "    print(\"Loading data...\")\n",
    "\n",
    "    fd = open(filename, \"rb\")\n",
    "    X, y = pickle.load(fd)\n",
    "    fd.close()\n",
    "    indices = np.random.permutation(len(X))\n",
    "    y = np.array(y)\n",
    "\n",
    "    print(\"\\tfilename = %s\" % filename)\n",
    "    print(\"\\tX size = %d\" % len(X))\n",
    "    print(\"\\ty size = %d\" % len(y))\n",
    "\n",
    "    # Preprocessing \n",
    "    print(\"Preprocessing...\")\n",
    "    X = [extract(permute_by_pt(jet)) for jet in X]\n",
    "    tf = RobustScaler().fit(np.vstack([jet[\"content\"] for jet in X]))\n",
    "\n",
    "    for jet in X:\n",
    "        jet[\"content\"] = tf.transform(jet[\"content\"])\n",
    "        \n",
    "    # Cropping\n",
    "    X_ = [j for j in X if 250 < j[\"pt\"] < 300 and 50 < j[\"mass\"] < 110]\n",
    "    y_ = [y[i] for i, j in enumerate(X) if 250 < j[\"pt\"] < 300 and 50 < j[\"mass\"] < 110]\n",
    "\n",
    "    X = X_\n",
    "    y = y_\n",
    "    \n",
    "    print(\"\\tX size = %d\" % len(X))\n",
    "    print(\"\\ty size = %d\" % len(y))\n",
    "        \n",
    "    return X, y, tf\n",
    "\n",
    "X, y, tf = load_test(\"../data/w-vs-qcd/anti-kt/antikt-test.pickle-py27-kt\")\n",
    "# X, y, tf = load_test(\"../data/w-vs-qcd/anti-kt/antikt-delphes-test.pickle-kt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from recnn.recnn import grnn_predict_simple\n",
    "from recnn.recnn import grnn_transform_simple\n",
    "\n",
    "import pickle\n",
    "\n",
    "fd = open(\"../models/delphes/w-kt-1.pickle\", \"rb\")\n",
    "# fd = open(\"../models/delphes/w-delphes-kt-1.pickle\", \"rb\")\n",
    "params = pickle.load(fd)\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91236886384659421"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y, grnn_predict_simple(params, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n",
      "200\n",
      "220\n",
      "240\n",
      "260\n",
      "280\n",
      "300\n",
      "320\n",
      "340\n",
      "360\n",
      "380\n",
      "400\n",
      "420\n",
      "440\n",
      "460\n",
      "480\n",
      "500\n",
      "520\n",
      "540\n",
      "560\n",
      "580\n",
      "600\n",
      "620\n",
      "640\n",
      "660\n",
      "680\n",
      "700\n",
      "720\n",
      "740\n",
      "760\n",
      "780\n",
      "800\n",
      "820\n",
      "840\n",
      "860\n",
      "880\n",
      "900\n",
      "920\n",
      "940\n",
      "960\n",
      "980\n",
      "1000\n",
      "1020\n",
      "1040\n",
      "1060\n",
      "1080\n",
      "1100\n",
      "1120\n",
      "1140\n",
      "1160\n",
      "1180\n",
      "1200\n",
      "1220\n",
      "1240\n",
      "1260\n",
      "1280\n",
      "1300\n",
      "1320\n",
      "1340\n",
      "1360\n",
      "1380\n",
      "1400\n",
      "1420\n",
      "1440\n",
      "1460\n",
      "1480\n",
      "1500\n",
      "1520\n",
      "1540\n",
      "1560\n",
      "1580\n",
      "1600\n",
      "1620\n",
      "1640\n",
      "1660\n",
      "1680\n",
      "1700\n",
      "1720\n",
      "1740\n",
      "1760\n",
      "1780\n",
      "1800\n",
      "1820\n",
      "1840\n",
      "1860\n",
      "1880\n",
      "1900\n",
      "1920\n",
      "1940\n",
      "1960\n",
      "1980\n",
      "2000\n",
      "2020\n",
      "2040\n",
      "2060\n",
      "2080\n",
      "2100\n",
      "2120\n",
      "2140\n",
      "2160\n",
      "2180\n",
      "2200\n",
      "2220\n",
      "2240\n",
      "2260\n",
      "2280\n",
      "2300\n",
      "2320\n",
      "2340\n",
      "2360\n",
      "2380\n",
      "2400\n",
      "2420\n",
      "2440\n",
      "2460\n",
      "2480\n",
      "2500\n",
      "2520\n",
      "2540\n",
      "2560\n",
      "2580\n",
      "2600\n",
      "2620\n",
      "2640\n",
      "2660\n",
      "2680\n",
      "2700\n",
      "2720\n",
      "2740\n",
      "2760\n",
      "2780\n",
      "2800\n",
      "2820\n",
      "2840\n",
      "2860\n",
      "2880\n",
      "2900\n",
      "2920\n",
      "2940\n",
      "2960\n",
      "2980\n",
      "3000\n",
      "3020\n",
      "3040\n",
      "3060\n",
      "3080\n",
      "3100\n",
      "3120\n",
      "3140\n",
      "3160\n",
      "3180\n",
      "3200\n",
      "3220\n",
      "3240\n",
      "3260\n",
      "3280\n",
      "3300\n",
      "3320\n",
      "3340\n",
      "3360\n",
      "3380\n",
      "3400\n",
      "3420\n",
      "3440\n",
      "3460\n",
      "3480\n",
      "3500\n",
      "3520\n",
      "3540\n",
      "3560\n",
      "3580\n",
      "3600\n",
      "3620\n",
      "3640\n",
      "3660\n",
      "3680\n",
      "3700\n",
      "3720\n",
      "3740\n",
      "3760\n",
      "3780\n",
      "3800\n",
      "3820\n",
      "3840\n",
      "3860\n",
      "3880\n",
      "3900\n",
      "3920\n",
      "3940\n",
      "3960\n",
      "3980\n",
      "4000\n",
      "4020\n",
      "4040\n",
      "4060\n",
      "4080\n",
      "4100\n",
      "4120\n",
      "4140\n",
      "4160\n",
      "4180\n",
      "4200\n",
      "4220\n",
      "4240\n",
      "4260\n",
      "4280\n",
      "4300\n",
      "4320\n",
      "4340\n",
      "4360\n",
      "4380\n",
      "4400\n",
      "4420\n",
      "4440\n",
      "4460\n",
      "4480\n",
      "4500\n",
      "4520\n",
      "4540\n",
      "4560\n",
      "4580\n",
      "4600\n",
      "4620\n",
      "4640\n",
      "4660\n",
      "4680\n",
      "4700\n",
      "4720\n",
      "4740\n",
      "4760\n",
      "4780\n",
      "4800\n",
      "4820\n",
      "4840\n",
      "4860\n",
      "4880\n",
      "4900\n",
      "4920\n",
      "4940\n",
      "4960\n",
      "4980\n",
      "5000\n",
      "5020\n",
      "5040\n",
      "5060\n",
      "5080\n",
      "5100\n",
      "5120\n",
      "5140\n",
      "5160\n",
      "5180\n",
      "5200\n",
      "5220\n",
      "5240\n",
      "5260\n",
      "5280\n",
      "5300\n",
      "5320\n",
      "5340\n",
      "5360\n",
      "5380\n",
      "5400\n",
      "5420\n",
      "5440\n",
      "5460\n",
      "5480\n",
      "5500\n",
      "5520\n",
      "5540\n",
      "5560\n",
      "5580\n",
      "5600\n",
      "5620\n",
      "5640\n",
      "5660\n",
      "5680\n",
      "5700\n",
      "5720\n",
      "5740\n",
      "5760\n",
      "5780\n",
      "5800\n",
      "5820\n",
      "5840\n",
      "5860\n",
      "5880\n",
      "5900\n",
      "5920\n",
      "5940\n",
      "5960\n",
      "5980\n",
      "6000\n",
      "6020\n",
      "6040\n",
      "6060\n",
      "6080\n",
      "6100\n",
      "6120\n",
      "6140\n",
      "6160\n",
      "6180\n",
      "6200\n",
      "6220\n",
      "6240\n",
      "6260\n",
      "6280\n",
      "6300\n",
      "6320\n",
      "6340\n",
      "6360\n",
      "6380\n",
      "6400\n",
      "6420\n",
      "6440\n",
      "6460\n",
      "6480\n",
      "6500\n",
      "6520\n",
      "6540\n",
      "6560\n",
      "6580\n",
      "6600\n",
      "6620\n",
      "6640\n",
      "6660\n",
      "6680\n",
      "6700\n",
      "6720\n",
      "6740\n",
      "6760\n",
      "6780\n",
      "6800\n",
      "6820\n",
      "6840\n",
      "6860\n",
      "6880\n",
      "6900\n",
      "6920\n",
      "6940\n",
      "6960\n",
      "6980\n",
      "7000\n",
      "7020\n",
      "7040\n",
      "7060\n",
      "7080\n",
      "7100\n",
      "7120\n",
      "7140\n",
      "7160\n",
      "7180\n",
      "7200\n",
      "7220\n",
      "7240\n",
      "7260\n",
      "7280\n",
      "7300\n",
      "7320\n",
      "7340\n",
      "7360\n",
      "7380\n",
      "7400\n",
      "7420\n",
      "7440\n",
      "7460\n",
      "7480\n",
      "7500\n",
      "7520\n",
      "7540\n",
      "7560\n",
      "7580\n",
      "7600\n",
      "7620\n",
      "7640\n",
      "7660\n",
      "7680\n",
      "7700\n",
      "7720\n",
      "7740\n",
      "7760\n",
      "7780\n",
      "7800\n",
      "7820\n",
      "7840\n",
      "7860\n",
      "7880\n",
      "7900\n",
      "7920\n",
      "7940\n",
      "7960\n",
      "7980\n",
      "8000\n",
      "8020\n",
      "8040\n",
      "8060\n",
      "8080\n",
      "8100\n",
      "8120\n",
      "8140\n",
      "8160\n",
      "8180\n",
      "8200\n",
      "8220\n",
      "8240\n",
      "8260\n",
      "8280\n",
      "8300\n",
      "8320\n",
      "8340\n",
      "8360\n",
      "8380\n",
      "8400\n",
      "8420\n",
      "8440\n",
      "8460\n",
      "8480\n",
      "8500\n",
      "8520\n",
      "8540\n",
      "8560\n",
      "8580\n",
      "8600\n",
      "8620\n",
      "8640\n",
      "8660\n",
      "8680\n",
      "8700\n",
      "8720\n",
      "8740\n",
      "8760\n",
      "8780\n",
      "8800\n",
      "8820\n",
      "8840\n",
      "8860\n",
      "8880\n",
      "8900\n",
      "8920\n",
      "8940\n",
      "8960\n",
      "8980\n",
      "9000\n",
      "9020\n",
      "9040\n",
      "9060\n",
      "9080\n",
      "9100\n",
      "9120\n",
      "9140\n",
      "9160\n",
      "9180\n",
      "9200\n",
      "9220\n",
      "9240\n",
      "9260\n",
      "9280\n",
      "9300\n",
      "9320\n",
      "9340\n",
      "9360\n",
      "9380\n",
      "9400\n",
      "9420\n",
      "9440\n",
      "9460\n",
      "9480\n",
      "9500\n",
      "9520\n",
      "9540\n",
      "9560\n",
      "9580\n",
      "9600\n",
      "9620\n",
      "9640\n",
      "9660\n",
      "9680\n",
      "9700\n",
      "9720\n",
      "9740\n",
      "9760\n",
      "9780\n",
      "9800\n",
      "9820\n",
      "9840\n",
      "9860\n",
      "9880\n",
      "9900\n",
      "9920\n",
      "9940\n",
      "9960\n",
      "9980\n"
     ]
    }
   ],
   "source": [
    "fd = open(\"../data/w-vs-qcd/anti-kt/antikt-event-test.pickle-kt\", \"rb\")\n",
    "# fd = open(\"../data/w-vs-qcd/anti-kt/antikt-delphes-event-test.pickle-kt\", \"rb\")\n",
    "\n",
    "events = []\n",
    "ys = []\n",
    "\n",
    "for i in range(10000):\n",
    "    if i % 20 == 0:\n",
    "        print(i)\n",
    "    e, y = pickle.load(fd)\n",
    "    \n",
    "    original_features = []\n",
    "    jets = []\n",
    "    \n",
    "    for phi, eta, pt, mass, jet in e:\n",
    "        original_features.append((phi, eta, pt, mass))\n",
    "        jet = extract(permute_by_pt(jet))\n",
    "        jet[\"content\"] = tf.transform(jet[\"content\"])\n",
    "        jets.append(jet)\n",
    "        \n",
    "    events.append((np.array(original_features), jets))\n",
    "    ys.append(y)\n",
    "    \n",
    "y = np.array(ys)\n",
    "    \n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0.89633835585353427)\n",
      "(1, 0.90857467634298705)\n",
      "(2, 0.74608642984345708)\n",
      "(3, 0.66896612675864509)\n",
      "(4, 0.60633652425346085)\n",
      "(5, 0.56672620266904805)\n",
      "(6, 0.53923182156927285)\n",
      "(7, 0.53130392125215686)\n",
      "(8, 0.52038552081542089)\n",
      "(9, 0.50883842035353677)\n"
     ]
    }
   ],
   "source": [
    "for l in range(10):\n",
    "    scores = []\n",
    "    ys = []\n",
    "    \n",
    "    for i in range(len(events)):\n",
    "        if l < len(events[i][1]):\n",
    "            scores.append(grnn_predict_simple(params, events[i][1][l:l+1])[0])\n",
    "            ys.append(y[i])\n",
    "    \n",
    "    print(l, roc_auc_score(ys, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96623099864924011"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for i in range(len(events)):\n",
    "    s = 0.0\n",
    "    \n",
    "    for l in range(5):\n",
    "        s += grnn_predict_simple(params, events[i][1][l:l+1])[0]\n",
    "        \n",
    "    scores.append(s)\n",
    "    \n",
    "roc_auc_score(y, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "tf = RobustScaler().fit(np.vstack([features for features, _ in events]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10, 44)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "\n",
    "for features, jets in events:\n",
    "    f = tf.transform(features)\n",
    "    h = grnn_transform_simple(params, jets)\n",
    "    X.append(np.hstack([f, h]))\n",
    "    \n",
    "X = [x_i[:10] for x_i in X]\n",
    "X = np.array(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from recnn.recnn import glorot_uniform\n",
    "from recnn.recnn import orthogonal\n",
    "from recnn.recnn import relu\n",
    "from recnn.recnn import sigmoid\n",
    "from recnn.recnn import check_random_state\n",
    "\n",
    "def vanilla_rnn_init(n_features, n_hidden, random_state=None):\n",
    "    rng = check_random_state(random_state)\n",
    "    return {\"init_h\": glorot_uniform(n_hidden, 0, rng),\n",
    "            \"W_h\": orthogonal((n_hidden, n_hidden), rng),\n",
    "            \"W_x\": glorot_uniform(n_hidden, n_features, rng),\n",
    "            \"b\": np.zeros(n_hidden),\n",
    "            \"W_clf\": [glorot_uniform(n_hidden, n_hidden, rng),\n",
    "                      glorot_uniform(n_hidden, n_hidden, rng),\n",
    "                      glorot_uniform(n_hidden, 0, rng)],\n",
    "            \"b_clf\": [np.zeros(n_hidden),\n",
    "                      np.zeros(n_hidden),\n",
    "                      np.ones(1)]}\n",
    "\n",
    "def vanilla_rnn_transform(params, jets):\n",
    "    h = np.tile(params[\"init_h\"], len(jets)).reshape(len(jets), -1)\n",
    "    \n",
    "    for t in range(jets.shape[1]):\n",
    "        xt = jets[:, t, :]\n",
    "        h = relu(np.dot(params[\"W_h\"], h.T).T + np.dot(params[\"W_x\"], xt.T).T + params[\"b\"])\n",
    "\n",
    "    return h\n",
    "\n",
    "def vanilla_rnn_predict(params, jets):\n",
    "    h = vanilla_rnn_transform(params, jets)\n",
    "\n",
    "    h = relu(np.dot(params[\"W_clf\"][0], h.T).T + params[\"b_clf\"][0])\n",
    "    h = relu(np.dot(params[\"W_clf\"][1], h.T).T + params[\"b_clf\"][1])\n",
    "    h = sigmoid(np.dot(params[\"W_clf\"][2], h.T).T + params[\"b_clf\"][2])\n",
    "\n",
    "    return h.ravel()\n",
    "\n",
    "\n",
    "\n",
    "def gru_init(n_features, n_hidden, random_state=None):\n",
    "    rng = check_random_state(random_state)\n",
    "    return {\"init_h\": glorot_uniform(n_hidden, 0, rng),\n",
    "            \"W_hh\": orthogonal((n_hidden, n_hidden), rng),\n",
    "            \"W_hx\": glorot_uniform(n_hidden, n_features, rng),\n",
    "            \"b_h\": np.zeros(n_hidden),\n",
    "            \"W_zh\": orthogonal((n_hidden, n_hidden), rng),\n",
    "            \"W_zx\": glorot_uniform(n_hidden, n_features, rng),\n",
    "            \"b_z\": np.zeros(n_hidden),\n",
    "            \"W_rh\": orthogonal((n_hidden, n_hidden), rng),\n",
    "            \"W_rx\": glorot_uniform(n_hidden, n_features, rng),\n",
    "            \"b_r\": np.zeros(n_hidden),\n",
    "            \"W_clf\": [glorot_uniform(n_hidden, n_hidden, rng),\n",
    "                      glorot_uniform(n_hidden, n_hidden, rng),\n",
    "                      glorot_uniform(n_hidden, 0, rng)],\n",
    "            \"b_clf\": [np.zeros(n_hidden),\n",
    "                      np.zeros(n_hidden),\n",
    "                      np.ones(1)]}\n",
    "\n",
    "def gru_transform(params, jets):\n",
    "    h = np.tile(params[\"init_h\"], len(jets)).reshape(len(jets), -1)\n",
    "    \n",
    "    for t in range(jets.shape[1]):\n",
    "        xt = jets[:, t, :]\n",
    "        zt = sigmoid(np.dot(params[\"W_zh\"], h.T).T + np.dot(params[\"W_zx\"], xt.T).T + params[\"b_z\"])\n",
    "        rt = sigmoid(np.dot(params[\"W_rh\"], h.T).T + np.dot(params[\"W_rx\"], xt.T).T + params[\"b_r\"])       \n",
    "        ht = relu(np.dot(params[\"W_hh\"], np.multiply(rt, h).T).T + np.dot(params[\"W_hx\"], xt.T).T + params[\"b_h\"])\n",
    "        h = np.multiply(1. - zt, h) + np.multiply(zt, ht)\n",
    "\n",
    "    return h\n",
    "\n",
    "def gru_predict(params, jets):\n",
    "    h = gru_transform(params, jets)\n",
    "\n",
    "    h = relu(np.dot(params[\"W_clf\"][0], h.T).T + params[\"b_clf\"][0])\n",
    "    h = relu(np.dot(params[\"W_clf\"][1], h.T).T + params[\"b_clf\"][1])\n",
    "    h = sigmoid(np.dot(params[\"W_clf\"][2], h.T).T + params[\"b_clf\"][2])\n",
    "\n",
    "    return h.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0\n",
      "step_size = 0.0005\n",
      "    0\t~loss(train)=1.1045\tloss(valid)=1.1608\troc_auc(valid)=0.4586\tbest_roc_auc(valid)=0.4586\n",
      "   25\t~loss(train)=1.0902\tloss(valid)=1.1455\troc_auc(valid)=0.6154\tbest_roc_auc(valid)=0.6154\n",
      "   50\t~loss(train)=1.0562\tloss(valid)=1.1089\troc_auc(valid)=0.8468\tbest_roc_auc(valid)=0.8468\n",
      "   75\t~loss(train)=0.9644\tloss(valid)=1.0101\troc_auc(valid)=0.9046\tbest_roc_auc(valid)=0.9046\n",
      "  100\t~loss(train)=0.7691\tloss(valid)=0.7985\troc_auc(valid)=0.9579\tbest_roc_auc(valid)=0.9579\n",
      "epoch = 1\n",
      "step_size = 0.0005\n",
      "    0\t~loss(train)=0.4704\tloss(valid)=0.4708\troc_auc(valid)=0.9734\tbest_roc_auc(valid)=0.9734\n",
      "   25\t~loss(train)=0.3787\tloss(valid)=0.3661\troc_auc(valid)=0.9784\tbest_roc_auc(valid)=0.9784\n",
      "   50\t~loss(train)=0.3423\tloss(valid)=0.3246\troc_auc(valid)=0.9786\tbest_roc_auc(valid)=0.9786\n",
      "   75\t~loss(train)=0.3114\tloss(valid)=0.2924\troc_auc(valid)=0.9794\tbest_roc_auc(valid)=0.9794\n",
      "  100\t~loss(train)=0.2814\tloss(valid)=0.2622\troc_auc(valid)=0.9795\tbest_roc_auc(valid)=0.9795\n",
      "epoch = 2\n",
      "step_size = 0.0005\n",
      "    0\t~loss(train)=0.2506\tloss(valid)=0.2291\troc_auc(valid)=0.9807\tbest_roc_auc(valid)=0.9807\n",
      "   25\t~loss(train)=0.2348\tloss(valid)=0.2126\troc_auc(valid)=0.9819\tbest_roc_auc(valid)=0.9819\n",
      "   50\t~loss(train)=0.2246\tloss(valid)=0.2000\troc_auc(valid)=0.9820\tbest_roc_auc(valid)=0.9820\n",
      "   75\t~loss(train)=0.2142\tloss(valid)=0.1882\troc_auc(valid)=0.9833\tbest_roc_auc(valid)=0.9833\n",
      "  100\t~loss(train)=0.2041\tloss(valid)=0.1787\troc_auc(valid)=0.9838\tbest_roc_auc(valid)=0.9838\n",
      "epoch = 3\n",
      "step_size = 0.0004\n",
      "    0\t~loss(train)=0.1900\tloss(valid)=0.1654\troc_auc(valid)=0.9865\tbest_roc_auc(valid)=0.9865\n",
      "   25\t~loss(train)=0.1853\tloss(valid)=0.1595\troc_auc(valid)=0.9882\tbest_roc_auc(valid)=0.9882\n",
      "   50\t~loss(train)=0.1891\tloss(valid)=0.1630\troc_auc(valid)=0.9867\tbest_roc_auc(valid)=0.9882\n",
      "   75\t~loss(train)=0.1792\tloss(valid)=0.1517\troc_auc(valid)=0.9887\tbest_roc_auc(valid)=0.9887\n",
      "  100\t~loss(train)=0.1914\tloss(valid)=0.1662\troc_auc(valid)=0.9871\tbest_roc_auc(valid)=0.9887\n",
      "epoch = 4\n",
      "step_size = 0.0004\n",
      "    0\t~loss(train)=0.1725\tloss(valid)=0.1465\troc_auc(valid)=0.9902\tbest_roc_auc(valid)=0.9902\n",
      "   25\t~loss(train)=0.1703\tloss(valid)=0.1441\troc_auc(valid)=0.9909\tbest_roc_auc(valid)=0.9909\n",
      "   50\t~loss(train)=0.1790\tloss(valid)=0.1532\troc_auc(valid)=0.9874\tbest_roc_auc(valid)=0.9909\n",
      "   75\t~loss(train)=0.1681\tloss(valid)=0.1417\troc_auc(valid)=0.9912\tbest_roc_auc(valid)=0.9912\n",
      "  100\t~loss(train)=0.1790\tloss(valid)=0.1533\troc_auc(valid)=0.9894\tbest_roc_auc(valid)=0.9912\n",
      "epoch = 5\n",
      "step_size = 0.0004\n",
      "    0\t~loss(train)=0.1616\tloss(valid)=0.1371\troc_auc(valid)=0.9921\tbest_roc_auc(valid)=0.9921\n",
      "   25\t~loss(train)=0.1605\tloss(valid)=0.1368\troc_auc(valid)=0.9923\tbest_roc_auc(valid)=0.9923\n",
      "   50\t~loss(train)=0.1629\tloss(valid)=0.1366\troc_auc(valid)=0.9914\tbest_roc_auc(valid)=0.9923\n",
      "   75\t~loss(train)=0.1622\tloss(valid)=0.1390\troc_auc(valid)=0.9915\tbest_roc_auc(valid)=0.9923\n",
      "  100\t~loss(train)=0.1711\tloss(valid)=0.1485\troc_auc(valid)=0.9903\tbest_roc_auc(valid)=0.9923\n",
      "epoch = 6\n",
      "step_size = 0.0004\n",
      "    0\t~loss(train)=0.1551\tloss(valid)=0.1307\troc_auc(valid)=0.9925\tbest_roc_auc(valid)=0.9925\n",
      "   25\t~loss(train)=0.1551\tloss(valid)=0.1309\troc_auc(valid)=0.9926\tbest_roc_auc(valid)=0.9926\n",
      "   50\t~loss(train)=0.1594\tloss(valid)=0.1339\troc_auc(valid)=0.9915\tbest_roc_auc(valid)=0.9926\n",
      "   75\t~loss(train)=0.1575\tloss(valid)=0.1346\troc_auc(valid)=0.9922\tbest_roc_auc(valid)=0.9926\n",
      "  100\t~loss(train)=0.1653\tloss(valid)=0.1421\troc_auc(valid)=0.9911\tbest_roc_auc(valid)=0.9926\n",
      "epoch = 7\n",
      "step_size = 0.0003\n",
      "    0\t~loss(train)=0.1511\tloss(valid)=0.1268\troc_auc(valid)=0.9928\tbest_roc_auc(valid)=0.9928\n",
      "   25\t~loss(train)=0.1508\tloss(valid)=0.1272\troc_auc(valid)=0.9924\tbest_roc_auc(valid)=0.9928\n",
      "   50\t~loss(train)=0.1559\tloss(valid)=0.1315\troc_auc(valid)=0.9916\tbest_roc_auc(valid)=0.9928\n",
      "   75\t~loss(train)=0.1534\tloss(valid)=0.1308\troc_auc(valid)=0.9923\tbest_roc_auc(valid)=0.9928\n",
      "  100\t~loss(train)=0.1587\tloss(valid)=0.1357\troc_auc(valid)=0.9917\tbest_roc_auc(valid)=0.9928\n",
      "epoch = 8\n",
      "step_size = 0.0003\n",
      "    0\t~loss(train)=0.1475\tloss(valid)=0.1237\troc_auc(valid)=0.9925\tbest_roc_auc(valid)=0.9928\n",
      "   25\t~loss(train)=0.1475\tloss(valid)=0.1243\troc_auc(valid)=0.9924\tbest_roc_auc(valid)=0.9928\n",
      "   50\t~loss(train)=0.1529\tloss(valid)=0.1292\troc_auc(valid)=0.9917\tbest_roc_auc(valid)=0.9928\n",
      "   75\t~loss(train)=0.1506\tloss(valid)=0.1285\troc_auc(valid)=0.9923\tbest_roc_auc(valid)=0.9928\n",
      "  100\t~loss(train)=0.1530\tloss(valid)=0.1303\troc_auc(valid)=0.9921\tbest_roc_auc(valid)=0.9928\n",
      "epoch = 9\n",
      "step_size = 0.0003\n",
      "    0\t~loss(train)=0.1447\tloss(valid)=0.1214\troc_auc(valid)=0.9926\tbest_roc_auc(valid)=0.9928\n",
      "   25\t~loss(train)=0.1447\tloss(valid)=0.1221\troc_auc(valid)=0.9924\tbest_roc_auc(valid)=0.9928\n",
      "   50\t~loss(train)=0.1503\tloss(valid)=0.1274\troc_auc(valid)=0.9917\tbest_roc_auc(valid)=0.9928\n",
      "   75\t~loss(train)=0.1477\tloss(valid)=0.1260\troc_auc(valid)=0.9923\tbest_roc_auc(valid)=0.9928\n",
      "  100\t~loss(train)=0.1498\tloss(valid)=0.1277\troc_auc(valid)=0.9922\tbest_roc_auc(valid)=0.9928\n",
      "epoch = 10\n",
      "step_size = 0.0003\n",
      "    0\t~loss(train)=0.1423\tloss(valid)=0.1195\troc_auc(valid)=0.9927\tbest_roc_auc(valid)=0.9928\n",
      "   25\t~loss(train)=0.1423\tloss(valid)=0.1201\troc_auc(valid)=0.9924\tbest_roc_auc(valid)=0.9928\n",
      "   50\t~loss(train)=0.1481\tloss(valid)=0.1259\troc_auc(valid)=0.9916\tbest_roc_auc(valid)=0.9928\n",
      "   75\t~loss(train)=0.1451\tloss(valid)=0.1238\troc_auc(valid)=0.9924\tbest_roc_auc(valid)=0.9928\n",
      "  100\t~loss(train)=0.1465\tloss(valid)=0.1250\troc_auc(valid)=0.9923\tbest_roc_auc(valid)=0.9928\n",
      "epoch = 11\n",
      "step_size = 0.0003\n",
      "    0\t~loss(train)=0.1395\tloss(valid)=0.1172\troc_auc(valid)=0.9932\tbest_roc_auc(valid)=0.9932\n",
      "   25\t~loss(train)=0.1397\tloss(valid)=0.1183\troc_auc(valid)=0.9932\tbest_roc_auc(valid)=0.9932\n",
      "   50\t~loss(train)=0.1454\tloss(valid)=0.1238\troc_auc(valid)=0.9918\tbest_roc_auc(valid)=0.9932\n",
      "   75\t~loss(train)=0.1417\tloss(valid)=0.1208\troc_auc(valid)=0.9926\tbest_roc_auc(valid)=0.9932\n",
      "  100\t~loss(train)=0.1433\tloss(valid)=0.1221\troc_auc(valid)=0.9925\tbest_roc_auc(valid)=0.9932\n",
      "epoch = 12\n",
      "step_size = 0.0003\n",
      "    0\t~loss(train)=0.1364\tloss(valid)=0.1154\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9936\n",
      "   25\t~loss(train)=0.1368\tloss(valid)=0.1164\troc_auc(valid)=0.9933\tbest_roc_auc(valid)=0.9936\n",
      "   50\t~loss(train)=0.1426\tloss(valid)=0.1223\troc_auc(valid)=0.9919\tbest_roc_auc(valid)=0.9936\n",
      "   75\t~loss(train)=0.1382\tloss(valid)=0.1180\troc_auc(valid)=0.9929\tbest_roc_auc(valid)=0.9936\n",
      "  100\t~loss(train)=0.1395\tloss(valid)=0.1190\troc_auc(valid)=0.9928\tbest_roc_auc(valid)=0.9936\n",
      "epoch = 13\n",
      "step_size = 0.0003\n",
      "    0\t~loss(train)=0.1344\tloss(valid)=0.1138\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9936\n",
      "   25\t~loss(train)=0.1348\tloss(valid)=0.1150\troc_auc(valid)=0.9933\tbest_roc_auc(valid)=0.9936\n",
      "   50\t~loss(train)=0.1411\tloss(valid)=0.1214\troc_auc(valid)=0.9918\tbest_roc_auc(valid)=0.9936\n",
      "   75\t~loss(train)=0.1360\tloss(valid)=0.1158\troc_auc(valid)=0.9931\tbest_roc_auc(valid)=0.9936\n",
      "  100\t~loss(train)=0.1376\tloss(valid)=0.1174\troc_auc(valid)=0.9929\tbest_roc_auc(valid)=0.9936\n",
      "epoch = 14\n",
      "step_size = 0.0002\n",
      "    0\t~loss(train)=0.1329\tloss(valid)=0.1127\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9937\n",
      "   25\t~loss(train)=0.1332\tloss(valid)=0.1136\troc_auc(valid)=0.9933\tbest_roc_auc(valid)=0.9937\n",
      "   50\t~loss(train)=0.1393\tloss(valid)=0.1201\troc_auc(valid)=0.9918\tbest_roc_auc(valid)=0.9937\n",
      "   75\t~loss(train)=0.1345\tloss(valid)=0.1148\troc_auc(valid)=0.9930\tbest_roc_auc(valid)=0.9937\n",
      "  100\t~loss(train)=0.1353\tloss(valid)=0.1154\troc_auc(valid)=0.9929\tbest_roc_auc(valid)=0.9937\n",
      "epoch = 15\n",
      "step_size = 0.0002\n",
      "    0\t~loss(train)=0.1314\tloss(valid)=0.1119\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9937\n",
      "   25\t~loss(train)=0.1316\tloss(valid)=0.1128\troc_auc(valid)=0.9932\tbest_roc_auc(valid)=0.9937\n",
      "   50\t~loss(train)=0.1378\tloss(valid)=0.1189\troc_auc(valid)=0.9919\tbest_roc_auc(valid)=0.9937\n",
      "   75\t~loss(train)=0.1328\tloss(valid)=0.1135\troc_auc(valid)=0.9930\tbest_roc_auc(valid)=0.9937\n",
      "  100\t~loss(train)=0.1339\tloss(valid)=0.1140\troc_auc(valid)=0.9930\tbest_roc_auc(valid)=0.9937\n",
      "epoch = 16\n",
      "step_size = 0.0002\n",
      "    0\t~loss(train)=0.1301\tloss(valid)=0.1105\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9938\n",
      "   25\t~loss(train)=0.1308\tloss(valid)=0.1117\troc_auc(valid)=0.9933\tbest_roc_auc(valid)=0.9938\n",
      "   50\t~loss(train)=0.1365\tloss(valid)=0.1175\troc_auc(valid)=0.9921\tbest_roc_auc(valid)=0.9938\n",
      "   75\t~loss(train)=0.1316\tloss(valid)=0.1123\troc_auc(valid)=0.9931\tbest_roc_auc(valid)=0.9938\n",
      "  100\t~loss(train)=0.1326\tloss(valid)=0.1133\troc_auc(valid)=0.9930\tbest_roc_auc(valid)=0.9938\n",
      "epoch = 17\n",
      "step_size = 0.0002\n",
      "    0\t~loss(train)=0.1288\tloss(valid)=0.1092\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9938\n",
      "   25\t~loss(train)=0.1295\tloss(valid)=0.1103\troc_auc(valid)=0.9934\tbest_roc_auc(valid)=0.9938\n",
      "   50\t~loss(train)=0.1356\tloss(valid)=0.1165\troc_auc(valid)=0.9922\tbest_roc_auc(valid)=0.9938\n",
      "   75\t~loss(train)=0.1304\tloss(valid)=0.1110\troc_auc(valid)=0.9932\tbest_roc_auc(valid)=0.9938\n",
      "  100\t~loss(train)=0.1308\tloss(valid)=0.1114\troc_auc(valid)=0.9932\tbest_roc_auc(valid)=0.9938\n",
      "epoch = 18\n",
      "step_size = 0.0002\n",
      "    0\t~loss(train)=0.1276\tloss(valid)=0.1083\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9938\n",
      "   25\t~loss(train)=0.1285\tloss(valid)=0.1096\troc_auc(valid)=0.9934\tbest_roc_auc(valid)=0.9938\n",
      "   50\t~loss(train)=0.1344\tloss(valid)=0.1156\troc_auc(valid)=0.9922\tbest_roc_auc(valid)=0.9938\n",
      "   75\t~loss(train)=0.1294\tloss(valid)=0.1102\troc_auc(valid)=0.9931\tbest_roc_auc(valid)=0.9938\n",
      "  100\t~loss(train)=0.1293\tloss(valid)=0.1100\troc_auc(valid)=0.9932\tbest_roc_auc(valid)=0.9938\n",
      "epoch = 19\n",
      "step_size = 0.0002\n",
      "    0\t~loss(train)=0.1265\tloss(valid)=0.1075\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9938\n",
      "   25\t~loss(train)=0.1275\tloss(valid)=0.1088\troc_auc(valid)=0.9933\tbest_roc_auc(valid)=0.9938\n",
      "   50\t~loss(train)=0.1331\tloss(valid)=0.1146\troc_auc(valid)=0.9923\tbest_roc_auc(valid)=0.9938\n",
      "   75\t~loss(train)=0.1281\tloss(valid)=0.1091\troc_auc(valid)=0.9932\tbest_roc_auc(valid)=0.9938\n",
      "  100\t~loss(train)=0.1281\tloss(valid)=0.1090\troc_auc(valid)=0.9932\tbest_roc_auc(valid)=0.9938\n",
      "epoch = 20\n",
      "step_size = 0.0002\n",
      "    0\t~loss(train)=0.1254\tloss(valid)=0.1065\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9938\n",
      "   25\t~loss(train)=0.1267\tloss(valid)=0.1084\troc_auc(valid)=0.9933\tbest_roc_auc(valid)=0.9938\n",
      "   50\t~loss(train)=0.1308\tloss(valid)=0.1121\troc_auc(valid)=0.9927\tbest_roc_auc(valid)=0.9938\n",
      "   75\t~loss(train)=0.1276\tloss(valid)=0.1086\troc_auc(valid)=0.9932\tbest_roc_auc(valid)=0.9938\n",
      "  100\t~loss(train)=0.1269\tloss(valid)=0.1079\troc_auc(valid)=0.9933\tbest_roc_auc(valid)=0.9938\n",
      "epoch = 21\n",
      "step_size = 0.0002\n",
      "    0\t~loss(train)=0.1245\tloss(valid)=0.1046\troc_auc(valid)=0.9940\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1259\tloss(valid)=0.1069\troc_auc(valid)=0.9934\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1297\tloss(valid)=0.1112\troc_auc(valid)=0.9927\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1266\tloss(valid)=0.1077\troc_auc(valid)=0.9932\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1253\tloss(valid)=0.1059\troc_auc(valid)=0.9934\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 22\n",
      "step_size = 0.0002\n",
      "    0\t~loss(train)=0.1237\tloss(valid)=0.1041\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1252\tloss(valid)=0.1060\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1288\tloss(valid)=0.1098\troc_auc(valid)=0.9929\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1257\tloss(valid)=0.1064\troc_auc(valid)=0.9934\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1251\tloss(valid)=0.1058\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 23\n",
      "step_size = 0.0002\n",
      "    0\t~loss(train)=0.1227\tloss(valid)=0.1036\troc_auc(valid)=0.9939\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1242\tloss(valid)=0.1055\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1277\tloss(valid)=0.1091\troc_auc(valid)=0.9930\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1248\tloss(valid)=0.1058\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1241\tloss(valid)=0.1050\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 24\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1219\tloss(valid)=0.1029\troc_auc(valid)=0.9939\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1235\tloss(valid)=0.1050\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1266\tloss(valid)=0.1083\troc_auc(valid)=0.9930\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1240\tloss(valid)=0.1053\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1232\tloss(valid)=0.1042\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 25\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1212\tloss(valid)=0.1026\troc_auc(valid)=0.9939\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1230\tloss(valid)=0.1050\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1256\tloss(valid)=0.1075\troc_auc(valid)=0.9930\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1235\tloss(valid)=0.1047\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1226\tloss(valid)=0.1035\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 26\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1206\tloss(valid)=0.1023\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1223\tloss(valid)=0.1046\troc_auc(valid)=0.9933\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1246\tloss(valid)=0.1069\troc_auc(valid)=0.9929\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1227\tloss(valid)=0.1045\troc_auc(valid)=0.9933\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1217\tloss(valid)=0.1031\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 27\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1199\tloss(valid)=0.1018\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1217\tloss(valid)=0.1043\troc_auc(valid)=0.9934\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1239\tloss(valid)=0.1065\troc_auc(valid)=0.9928\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1221\tloss(valid)=0.1040\troc_auc(valid)=0.9933\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1213\tloss(valid)=0.1025\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 28\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1193\tloss(valid)=0.1013\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1215\tloss(valid)=0.1035\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1233\tloss(valid)=0.1055\troc_auc(valid)=0.9930\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1217\tloss(valid)=0.1034\troc_auc(valid)=0.9934\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1206\tloss(valid)=0.1020\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 29\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1188\tloss(valid)=0.1007\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1206\tloss(valid)=0.1029\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1224\tloss(valid)=0.1052\troc_auc(valid)=0.9930\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1210\tloss(valid)=0.1029\troc_auc(valid)=0.9934\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1200\tloss(valid)=0.1015\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 30\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1186\tloss(valid)=0.1003\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1203\tloss(valid)=0.1024\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1220\tloss(valid)=0.1045\troc_auc(valid)=0.9930\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1206\tloss(valid)=0.1024\troc_auc(valid)=0.9934\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1195\tloss(valid)=0.1010\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 31\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1180\tloss(valid)=0.1002\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1195\tloss(valid)=0.1021\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1213\tloss(valid)=0.1039\troc_auc(valid)=0.9931\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1200\tloss(valid)=0.1019\troc_auc(valid)=0.9934\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1190\tloss(valid)=0.1006\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 32\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1175\tloss(valid)=0.0997\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1190\tloss(valid)=0.1015\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1207\tloss(valid)=0.1035\troc_auc(valid)=0.9931\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1194\tloss(valid)=0.1015\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1185\tloss(valid)=0.1002\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 33\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1171\tloss(valid)=0.0994\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1185\tloss(valid)=0.1012\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1201\tloss(valid)=0.1031\troc_auc(valid)=0.9931\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1188\tloss(valid)=0.1011\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1180\tloss(valid)=0.0998\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 34\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1169\tloss(valid)=0.0987\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1183\tloss(valid)=0.1005\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1197\tloss(valid)=0.1024\troc_auc(valid)=0.9932\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1183\tloss(valid)=0.1004\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1176\tloss(valid)=0.0993\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 35\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1163\tloss(valid)=0.0986\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1176\tloss(valid)=0.1000\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1191\tloss(valid)=0.1020\troc_auc(valid)=0.9932\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1178\tloss(valid)=0.1000\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1171\tloss(valid)=0.0989\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 36\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1160\tloss(valid)=0.0983\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1171\tloss(valid)=0.0996\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1186\tloss(valid)=0.1017\troc_auc(valid)=0.9932\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1174\tloss(valid)=0.0995\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1167\tloss(valid)=0.0986\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 37\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1156\tloss(valid)=0.0980\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1166\tloss(valid)=0.0990\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1183\tloss(valid)=0.1013\troc_auc(valid)=0.9932\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1170\tloss(valid)=0.0992\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1163\tloss(valid)=0.0983\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 38\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1153\tloss(valid)=0.0977\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1161\tloss(valid)=0.0986\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1178\tloss(valid)=0.1009\troc_auc(valid)=0.9933\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1166\tloss(valid)=0.0988\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1159\tloss(valid)=0.0979\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 39\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1150\tloss(valid)=0.0974\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1157\tloss(valid)=0.0980\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1174\tloss(valid)=0.1004\troc_auc(valid)=0.9933\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1162\tloss(valid)=0.0985\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1155\tloss(valid)=0.0976\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 40\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1146\tloss(valid)=0.0971\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1153\tloss(valid)=0.0976\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1170\tloss(valid)=0.1000\troc_auc(valid)=0.9934\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1159\tloss(valid)=0.0981\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1151\tloss(valid)=0.0972\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 41\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1144\tloss(valid)=0.0968\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1149\tloss(valid)=0.0972\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1165\tloss(valid)=0.0995\troc_auc(valid)=0.9934\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1154\tloss(valid)=0.0977\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1148\tloss(valid)=0.0970\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 42\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1140\tloss(valid)=0.0965\troc_auc(valid)=0.9939\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1146\tloss(valid)=0.0971\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1161\tloss(valid)=0.0991\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1150\tloss(valid)=0.0974\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1144\tloss(valid)=0.0966\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 43\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1138\tloss(valid)=0.0963\troc_auc(valid)=0.9939\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1144\tloss(valid)=0.0969\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1158\tloss(valid)=0.0987\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1146\tloss(valid)=0.0970\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1141\tloss(valid)=0.0965\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 44\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1135\tloss(valid)=0.0961\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1140\tloss(valid)=0.0966\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1157\tloss(valid)=0.0986\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1143\tloss(valid)=0.0968\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1138\tloss(valid)=0.0963\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 45\n",
      "step_size = 0.0000\n",
      "    0\t~loss(train)=0.1133\tloss(valid)=0.0960\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1137\tloss(valid)=0.0964\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1152\tloss(valid)=0.0980\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1140\tloss(valid)=0.0965\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1135\tloss(valid)=0.0960\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 46\n",
      "step_size = 0.0000\n",
      "    0\t~loss(train)=0.1131\tloss(valid)=0.0958\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1134\tloss(valid)=0.0961\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1150\tloss(valid)=0.0979\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1137\tloss(valid)=0.0964\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1132\tloss(valid)=0.0958\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 47\n",
      "step_size = 0.0000\n",
      "    0\t~loss(train)=0.1129\tloss(valid)=0.0957\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1131\tloss(valid)=0.0959\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1145\tloss(valid)=0.0974\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1133\tloss(valid)=0.0960\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1130\tloss(valid)=0.0956\troc_auc(valid)=0.9939\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 48\n",
      "step_size = 0.0000\n",
      "    0\t~loss(train)=0.1127\tloss(valid)=0.0955\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1129\tloss(valid)=0.0957\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1142\tloss(valid)=0.0971\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1129\tloss(valid)=0.0956\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1128\tloss(valid)=0.0955\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 49\n",
      "step_size = 0.0000\n",
      "    0\t~loss(train)=0.1125\tloss(valid)=0.0954\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1127\tloss(valid)=0.0956\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1138\tloss(valid)=0.0968\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1127\tloss(valid)=0.0954\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1125\tloss(valid)=0.0951\troc_auc(valid)=0.9939\tbest_roc_auc(valid)=0.9940\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "import autograd as ag\n",
    "from recnn.recnn import log_loss\n",
    "from recnn.recnn import adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n",
    "                                                      test_size=2000,\n",
    "                                                      random_state=1)\n",
    "\n",
    "init = gru_init\n",
    "predict = gru_predict\n",
    "\n",
    "n_epochs = 50\n",
    "batch_size = 64\n",
    "step_size = 0.0005\n",
    "decay = 0.95\n",
    "\n",
    "trained_params = init(44, 5, random_state=1)\n",
    "n_batches = int(np.ceil(len(X_train) / batch_size))\n",
    "best_score = [-np.inf]  # yuck, but works\n",
    "best_params = [trained_params]\n",
    "\n",
    "def loss(X, y, params):\n",
    "    y_pred = predict(params, X)\n",
    "    l = log_loss(y, y_pred).mean()\n",
    "    return l\n",
    "\n",
    "def objective(params, iteration):\n",
    "    rng = check_random_state(iteration % n_batches)\n",
    "    start = rng.randint(len(X_train) - batch_size)\n",
    "    idx = slice(start, start+batch_size)\n",
    "    return loss(X_train[idx], y_train[idx], params)\n",
    "\n",
    "def callback(params, iteration, gradient):\n",
    "    if iteration % 25 == 0:\n",
    "        roc_auc = roc_auc_score(y_valid, predict(params, X_valid))\n",
    "\n",
    "        if roc_auc > best_score[0]:\n",
    "            best_score[0] = roc_auc\n",
    "            best_params[0] = copy.deepcopy(params)\n",
    "\n",
    "        print(\n",
    "            \"%5d\\t~loss(train)=%.4f\\tloss(valid)=%.4f\"\n",
    "            \"\\troc_auc(valid)=%.4f\\tbest_roc_auc(valid)=%.4f\" % (\n",
    "                iteration,\n",
    "                loss(X_train[:5000], y_train[:5000], params),\n",
    "                loss(X_valid, y_valid, params),\n",
    "                roc_auc,\n",
    "                best_score[0]))\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    print(\"epoch = %d\" % i)\n",
    "    print(\"step_size = %.4f\" % step_size)\n",
    "\n",
    "    trained_params = adam(ag.grad(objective),\n",
    "                          trained_params,\n",
    "                          step_size=step_size,\n",
    "                          num_iters=1 * n_batches,\n",
    "                          callback=callback)\n",
    "    step_size = step_size * decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "267.412839137\n",
      "39.415250207\n",
      "23.5980411797\n",
      "21.2168321198\n",
      "20.7118046871\n",
      "16.7117347687\n",
      "19.1275465395\n",
      "17.9334322172\n",
      "14.2339908259\n",
      "13.613350919\n",
      "13.4888093673\n",
      "11.0020772977\n",
      "12.8344669934\n",
      "9.44970514663\n",
      "7.49511069272\n",
      "6.82304032534\n",
      "4.56652662732\n",
      "4.55178909615\n",
      "4.20511455536\n",
      "3.62597806086\n",
      "2.83713767679\n",
      "2.89979446348\n",
      "2.79273584374\n",
      "2.68638084093\n",
      "2.54697387992\n",
      "2.52295906405\n",
      "2.14501939776\n",
      "1.98560288337\n",
      "1.76643438865\n",
      "1.76915223772\n",
      "1.46660150246\n",
      "1.38870984055\n",
      "1.24643686425\n",
      "0.892840041959\n",
      "0.867205290703\n",
      "0.710562603467\n",
      "0.614620043501\n",
      "0.54687411684\n",
      "0.473092426327\n",
      "0.405385085637\n",
      "0.402666616646\n",
      "0.311493311602\n",
      "0.229915034303\n",
      "0.104200466638\n",
      "0.102050561206\n",
      "0.0564801816809\n",
      "0.0257452279404\n"
     ]
    }
   ],
   "source": [
    "features, jets = events[5]\n",
    "print(y[5])\n",
    "for j in jets:\n",
    "    print(j[\"pt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0.56420626256825046)\n",
      "(1, 0.96776727871069124)\n",
      "(2, 0.83230303329212141)\n",
      "(3, 0.7687326307493052)\n",
      "(4, 0.71567674862706998)\n",
      "(5, 0.66643188665727549)\n",
      "(6, 0.63598322543932906)\n",
      "(7, 0.61117750444710017)\n",
      "(8, 0.59528634381145373)\n",
      "(9, 0.58424578336983135)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i, roc_auc_score(y, [-jets[i][\"pt\"] for _, jets in events]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAHpCAYAAAB9dW61AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJVEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe9ad4b2790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 5\n",
    "plt.hist([jets[n][\"pt\"] for i, (f, jets) in enumerate(events) if y[i] == 1], \n",
    "         histtype=\"step\", bins=30, normed=1, label=\"w\")\n",
    "plt.hist([jets[n][\"pt\"] for i, (f, jets) in enumerate(events) if y[i] == 0], \n",
    "         histtype=\"step\", bins=30, normed=1, label=\"qcd\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"pt (%d-th jet)\" % n)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
