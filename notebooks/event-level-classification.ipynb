{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\tfilename = ../data/w-vs-qcd/anti-kt/antikt-test.pickle-py27-kt\n",
      "\tX size = 20000\n",
      "\ty size = 20000\n",
      "Preprocessing...\n",
      "\tX size = 7690\n",
      "\ty size = 7690\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from recnn.preprocessing import extract, permute_by_pt\n",
    "\n",
    "def load_test(filename):\n",
    "    # Make training data\n",
    "    print(\"Loading data...\")\n",
    "\n",
    "    fd = open(filename, \"rb\")\n",
    "    X, y = pickle.load(fd)\n",
    "    fd.close()\n",
    "    indices = np.random.permutation(len(X))\n",
    "    y = np.array(y)\n",
    "\n",
    "    print(\"\\tfilename = %s\" % filename)\n",
    "    print(\"\\tX size = %d\" % len(X))\n",
    "    print(\"\\ty size = %d\" % len(y))\n",
    "\n",
    "    # Preprocessing \n",
    "    print(\"Preprocessing...\")\n",
    "    X = [extract(permute_by_pt(jet)) for jet in X]\n",
    "    tf = RobustScaler().fit(np.vstack([jet[\"content\"] for jet in X]))\n",
    "\n",
    "    for jet in X:\n",
    "        jet[\"content\"] = tf.transform(jet[\"content\"])\n",
    "        \n",
    "    # Cropping\n",
    "    X_ = [j for j in X if 250 < j[\"pt\"] < 300 and 50 < j[\"mass\"] < 110]\n",
    "    y_ = [y[i] for i, j in enumerate(X) if 250 < j[\"pt\"] < 300 and 50 < j[\"mass\"] < 110]\n",
    "\n",
    "    X = X_\n",
    "    y = y_\n",
    "    \n",
    "    print(\"\\tX size = %d\" % len(X))\n",
    "    print(\"\\ty size = %d\" % len(y))\n",
    "        \n",
    "    return X, y, tf\n",
    "\n",
    "X, y, tf = load_test(\"../data/w-vs-qcd/anti-kt/antikt-test.pickle-py27-kt\")\n",
    "# X, y, tf = load_test(\"../data/w-vs-qcd/anti-kt/antikt-delphes-test.pickle-kt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from recnn.recnn import grnn_predict_simple\n",
    "from recnn.recnn import grnn_transform_simple\n",
    "\n",
    "import pickle\n",
    "\n",
    "fd = open(\"../models/delphes/w-kt-1.pickle\", \"rb\")\n",
    "# fd = open(\"../models/delphes/w-delphes-kt-1.pickle\", \"rb\")\n",
    "params = pickle.load(fd)\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91236886384659421"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y, grnn_predict_simple(params, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n",
      "200\n",
      "220\n",
      "240\n",
      "260\n",
      "280\n",
      "300\n",
      "320\n",
      "340\n",
      "360\n",
      "380\n",
      "400\n",
      "420\n",
      "440\n",
      "460\n",
      "480\n",
      "500\n",
      "520\n",
      "540\n",
      "560\n",
      "580\n",
      "600\n",
      "620\n",
      "640\n",
      "660\n",
      "680\n",
      "700\n",
      "720\n",
      "740\n",
      "760\n",
      "780\n",
      "800\n",
      "820\n",
      "840\n",
      "860\n",
      "880\n",
      "900\n",
      "920\n",
      "940\n",
      "960\n",
      "980\n",
      "1000\n",
      "1020\n",
      "1040\n",
      "1060\n",
      "1080\n",
      "1100\n",
      "1120\n",
      "1140\n",
      "1160\n",
      "1180\n",
      "1200\n",
      "1220\n",
      "1240\n",
      "1260\n",
      "1280\n",
      "1300\n",
      "1320\n",
      "1340\n",
      "1360\n",
      "1380\n",
      "1400\n",
      "1420\n",
      "1440\n",
      "1460\n",
      "1480\n",
      "1500\n",
      "1520\n",
      "1540\n",
      "1560\n",
      "1580\n",
      "1600\n",
      "1620\n",
      "1640\n",
      "1660\n",
      "1680\n",
      "1700\n",
      "1720\n",
      "1740\n",
      "1760\n",
      "1780\n",
      "1800\n",
      "1820\n",
      "1840\n",
      "1860\n",
      "1880\n",
      "1900\n",
      "1920\n",
      "1940\n",
      "1960\n",
      "1980\n",
      "2000\n",
      "2020\n",
      "2040\n",
      "2060\n",
      "2080\n",
      "2100\n",
      "2120\n",
      "2140\n",
      "2160\n",
      "2180\n",
      "2200\n",
      "2220\n",
      "2240\n",
      "2260\n",
      "2280\n",
      "2300\n",
      "2320\n",
      "2340\n",
      "2360\n",
      "2380\n",
      "2400\n",
      "2420\n",
      "2440\n",
      "2460\n",
      "2480\n",
      "2500\n",
      "2520\n",
      "2540\n",
      "2560\n",
      "2580\n",
      "2600\n",
      "2620\n",
      "2640\n",
      "2660\n",
      "2680\n",
      "2700\n",
      "2720\n",
      "2740\n",
      "2760\n",
      "2780\n",
      "2800\n",
      "2820\n",
      "2840\n",
      "2860\n",
      "2880\n",
      "2900\n",
      "2920\n",
      "2940\n",
      "2960\n",
      "2980\n",
      "3000\n",
      "3020\n",
      "3040\n",
      "3060\n",
      "3080\n",
      "3100\n",
      "3120\n",
      "3140\n",
      "3160\n",
      "3180\n",
      "3200\n",
      "3220\n",
      "3240\n",
      "3260\n",
      "3280\n",
      "3300\n",
      "3320\n",
      "3340\n",
      "3360\n",
      "3380\n",
      "3400\n",
      "3420\n",
      "3440\n",
      "3460\n",
      "3480\n",
      "3500\n",
      "3520\n",
      "3540\n",
      "3560\n",
      "3580\n",
      "3600\n",
      "3620\n",
      "3640\n",
      "3660\n",
      "3680\n",
      "3700\n",
      "3720\n",
      "3740\n",
      "3760\n",
      "3780\n",
      "3800\n",
      "3820\n",
      "3840\n",
      "3860\n",
      "3880\n",
      "3900\n",
      "3920\n",
      "3940\n",
      "3960\n",
      "3980\n",
      "4000\n",
      "4020\n",
      "4040\n",
      "4060\n",
      "4080\n",
      "4100\n",
      "4120\n",
      "4140\n",
      "4160\n",
      "4180\n",
      "4200\n",
      "4220\n",
      "4240\n",
      "4260\n",
      "4280\n",
      "4300\n",
      "4320\n",
      "4340\n",
      "4360\n",
      "4380\n",
      "4400\n",
      "4420\n",
      "4440\n",
      "4460\n",
      "4480\n",
      "4500\n",
      "4520\n",
      "4540\n",
      "4560\n",
      "4580\n",
      "4600\n",
      "4620\n",
      "4640\n",
      "4660\n",
      "4680\n",
      "4700\n",
      "4720\n",
      "4740\n",
      "4760\n",
      "4780\n",
      "4800\n",
      "4820\n",
      "4840\n",
      "4860\n",
      "4880\n",
      "4900\n",
      "4920\n",
      "4940\n",
      "4960\n",
      "4980\n",
      "5000\n",
      "5020\n",
      "5040\n",
      "5060\n",
      "5080\n",
      "5100\n",
      "5120\n",
      "5140\n",
      "5160\n",
      "5180\n",
      "5200\n",
      "5220\n",
      "5240\n",
      "5260\n",
      "5280\n",
      "5300\n",
      "5320\n",
      "5340\n",
      "5360\n",
      "5380\n",
      "5400\n",
      "5420\n",
      "5440\n",
      "5460\n",
      "5480\n",
      "5500\n",
      "5520\n",
      "5540\n",
      "5560\n",
      "5580\n",
      "5600\n",
      "5620\n",
      "5640\n",
      "5660\n",
      "5680\n",
      "5700\n",
      "5720\n",
      "5740\n",
      "5760\n",
      "5780\n",
      "5800\n",
      "5820\n",
      "5840\n",
      "5860\n",
      "5880\n",
      "5900\n",
      "5920\n",
      "5940\n",
      "5960\n",
      "5980\n",
      "6000\n",
      "6020\n",
      "6040\n",
      "6060\n",
      "6080\n",
      "6100\n",
      "6120\n",
      "6140\n",
      "6160\n",
      "6180\n",
      "6200\n",
      "6220\n",
      "6240\n",
      "6260\n",
      "6280\n",
      "6300\n",
      "6320\n",
      "6340\n",
      "6360\n",
      "6380\n",
      "6400\n",
      "6420\n",
      "6440\n",
      "6460\n",
      "6480\n",
      "6500\n",
      "6520\n",
      "6540\n",
      "6560\n",
      "6580\n",
      "6600\n",
      "6620\n",
      "6640\n",
      "6660\n",
      "6680\n",
      "6700\n",
      "6720\n",
      "6740\n",
      "6760\n",
      "6780\n",
      "6800\n",
      "6820\n",
      "6840\n",
      "6860\n",
      "6880\n",
      "6900\n",
      "6920\n",
      "6940\n",
      "6960\n",
      "6980\n",
      "7000\n",
      "7020\n",
      "7040\n",
      "7060\n",
      "7080\n",
      "7100\n",
      "7120\n",
      "7140\n",
      "7160\n",
      "7180\n",
      "7200\n",
      "7220\n",
      "7240\n",
      "7260\n",
      "7280\n",
      "7300\n",
      "7320\n",
      "7340\n",
      "7360\n",
      "7380\n",
      "7400\n",
      "7420\n",
      "7440\n",
      "7460\n",
      "7480\n",
      "7500\n",
      "7520\n",
      "7540\n",
      "7560\n",
      "7580\n",
      "7600\n",
      "7620\n",
      "7640\n",
      "7660\n",
      "7680\n",
      "7700\n",
      "7720\n",
      "7740\n",
      "7760\n",
      "7780\n",
      "7800\n",
      "7820\n",
      "7840\n",
      "7860\n",
      "7880\n",
      "7900\n",
      "7920\n",
      "7940\n",
      "7960\n",
      "7980\n",
      "8000\n",
      "8020\n",
      "8040\n",
      "8060\n",
      "8080\n",
      "8100\n",
      "8120\n",
      "8140\n",
      "8160\n",
      "8180\n",
      "8200\n",
      "8220\n",
      "8240\n",
      "8260\n",
      "8280\n",
      "8300\n",
      "8320\n",
      "8340\n",
      "8360\n",
      "8380\n",
      "8400\n",
      "8420\n",
      "8440\n",
      "8460\n",
      "8480\n",
      "8500\n",
      "8520\n",
      "8540\n",
      "8560\n",
      "8580\n",
      "8600\n",
      "8620\n",
      "8640\n",
      "8660\n",
      "8680\n",
      "8700\n",
      "8720\n",
      "8740\n",
      "8760\n",
      "8780\n",
      "8800\n",
      "8820\n",
      "8840\n",
      "8860\n",
      "8880\n",
      "8900\n",
      "8920\n",
      "8940\n",
      "8960\n",
      "8980\n",
      "9000\n",
      "9020\n",
      "9040\n",
      "9060\n",
      "9080\n",
      "9100\n",
      "9120\n",
      "9140\n",
      "9160\n",
      "9180\n",
      "9200\n",
      "9220\n",
      "9240\n",
      "9260\n",
      "9280\n",
      "9300\n",
      "9320\n",
      "9340\n",
      "9360\n",
      "9380\n",
      "9400\n",
      "9420\n",
      "9440\n",
      "9460\n",
      "9480\n",
      "9500\n",
      "9520\n",
      "9540\n",
      "9560\n",
      "9580\n",
      "9600\n",
      "9620\n",
      "9640\n",
      "9660\n",
      "9680\n",
      "9700\n",
      "9720\n",
      "9740\n",
      "9760\n",
      "9780\n",
      "9800\n",
      "9820\n",
      "9840\n",
      "9860\n",
      "9880\n",
      "9900\n",
      "9920\n",
      "9940\n",
      "9960\n",
      "9980\n"
     ]
    }
   ],
   "source": [
    "fd = open(\"../data/w-vs-qcd/anti-kt/antikt-event-test.pickle-kt\", \"rb\")\n",
    "# fd = open(\"../data/w-vs-qcd/anti-kt/antikt-delphes-event-test.pickle-kt\", \"rb\")\n",
    "\n",
    "events = []\n",
    "ys = []\n",
    "\n",
    "for i in range(10000):\n",
    "    if i % 20 == 0:\n",
    "        print(i)\n",
    "    e, y = pickle.load(fd)\n",
    "    \n",
    "    original_features = []\n",
    "    jets = []\n",
    "    \n",
    "    for phi, eta, pt, mass, jet in e:\n",
    "        original_features.append((phi, eta, pt, mass))\n",
    "        jet = extract(permute_by_pt(jet))\n",
    "        jet[\"content\"] = tf.transform(jet[\"content\"])\n",
    "        jets.append(jet)\n",
    "        \n",
    "    events.append((np.array(original_features), jets))\n",
    "    ys.append(y)\n",
    "    \n",
    "y = np.array(ys)\n",
    "    \n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0.89633835585353427)\n",
      "(1, 0.90857467634298705)\n",
      "(2, 0.74608642984345708)\n",
      "(3, 0.66896612675864509)\n",
      "(4, 0.60633652425346085)\n",
      "(5, 0.56672620266904805)\n",
      "(6, 0.53923182156927285)\n",
      "(7, 0.53130392125215686)\n",
      "(8, 0.52038552081542089)\n",
      "(9, 0.50883842035353677)\n"
     ]
    }
   ],
   "source": [
    "for l in range(10):\n",
    "    scores = []\n",
    "    ys = []\n",
    "    \n",
    "    for i in range(len(events)):\n",
    "        if l < len(events[i][1]):\n",
    "            scores.append(grnn_predict_simple(params, events[i][1][l:l+1])[0])\n",
    "            ys.append(y[i])\n",
    "    \n",
    "    print(l, roc_auc_score(ys, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96623099864924011"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for i in range(len(events)):\n",
    "    s = 0.0\n",
    "    \n",
    "    for l in range(5):\n",
    "        s += grnn_predict_simple(params, events[i][1][l:l+1])[0]\n",
    "        \n",
    "    scores.append(s)\n",
    "    \n",
    "roc_auc_score(y, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "tf = RobustScaler().fit(np.vstack([features for features, _ in events]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10, 44)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "\n",
    "for features, jets in events:\n",
    "    f = tf.transform(features)\n",
    "    h = grnn_transform_simple(params, jets)\n",
    "    X.append(np.hstack([f, h]))\n",
    "    \n",
    "X = [x_i[:10] for x_i in X]\n",
    "X = np.array(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from recnn.recnn import glorot_uniform\n",
    "from recnn.recnn import orthogonal\n",
    "from recnn.recnn import relu\n",
    "from recnn.recnn import sigmoid\n",
    "from recnn.recnn import check_random_state\n",
    "\n",
    "def vanilla_rnn_init(n_features, n_hidden, random_state=None):\n",
    "    rng = check_random_state(random_state)\n",
    "    return {\"init_h\": glorot_uniform(n_hidden, 0, rng),\n",
    "            \"W_h\": orthogonal((n_hidden, n_hidden), rng),\n",
    "            \"W_x\": glorot_uniform(n_hidden, n_features, rng),\n",
    "            \"b\": np.zeros(n_hidden),\n",
    "            \"W_clf\": [glorot_uniform(n_hidden, n_hidden, rng),\n",
    "                      glorot_uniform(n_hidden, n_hidden, rng),\n",
    "                      glorot_uniform(n_hidden, 0, rng)],\n",
    "            \"b_clf\": [np.zeros(n_hidden),\n",
    "                      np.zeros(n_hidden),\n",
    "                      np.ones(1)]}\n",
    "\n",
    "def vanilla_rnn_transform(params, jets):\n",
    "    h = np.tile(params[\"init_h\"], len(jets)).reshape(len(jets), -1)\n",
    "    \n",
    "    for t in range(jets.shape[1]):\n",
    "        xt = jets[:, t, :]\n",
    "        h = relu(np.dot(params[\"W_h\"], h.T).T + np.dot(params[\"W_x\"], xt.T).T + params[\"b\"])\n",
    "\n",
    "    return h\n",
    "\n",
    "def vanilla_rnn_predict(params, jets):\n",
    "    h = vanilla_rnn_transform(params, jets)\n",
    "\n",
    "    h = relu(np.dot(params[\"W_clf\"][0], h.T).T + params[\"b_clf\"][0])\n",
    "    h = relu(np.dot(params[\"W_clf\"][1], h.T).T + params[\"b_clf\"][1])\n",
    "    h = sigmoid(np.dot(params[\"W_clf\"][2], h.T).T + params[\"b_clf\"][2])\n",
    "\n",
    "    return h.ravel()\n",
    "\n",
    "\n",
    "\n",
    "def gru_init(n_features, n_hidden, random_state=None):\n",
    "    rng = check_random_state(random_state)\n",
    "    return {\"init_h\": glorot_uniform(n_hidden, 0, rng),\n",
    "            \"W_hh\": orthogonal((n_hidden, n_hidden), rng),\n",
    "            \"W_hx\": glorot_uniform(n_hidden, n_features, rng),\n",
    "            \"b_h\": np.zeros(n_hidden),\n",
    "            \"W_zh\": orthogonal((n_hidden, n_hidden), rng),\n",
    "            \"W_zx\": glorot_uniform(n_hidden, n_features, rng),\n",
    "            \"b_z\": np.zeros(n_hidden),\n",
    "            \"W_rh\": orthogonal((n_hidden, n_hidden), rng),\n",
    "            \"W_rx\": glorot_uniform(n_hidden, n_features, rng),\n",
    "            \"b_r\": np.zeros(n_hidden),\n",
    "            \"W_clf\": [glorot_uniform(n_hidden, n_hidden, rng),\n",
    "                      glorot_uniform(n_hidden, n_hidden, rng),\n",
    "                      glorot_uniform(n_hidden, 0, rng)],\n",
    "            \"b_clf\": [np.zeros(n_hidden),\n",
    "                      np.zeros(n_hidden),\n",
    "                      np.ones(1)]}\n",
    "\n",
    "def gru_transform(params, jets):\n",
    "    h = np.tile(params[\"init_h\"], len(jets)).reshape(len(jets), -1)\n",
    "    \n",
    "    for t in range(jets.shape[1]):\n",
    "        xt = jets[:, t, :]\n",
    "        zt = sigmoid(np.dot(params[\"W_zh\"], h.T).T + np.dot(params[\"W_zx\"], xt.T).T + params[\"b_z\"])\n",
    "        rt = sigmoid(np.dot(params[\"W_rh\"], h.T).T + np.dot(params[\"W_rx\"], xt.T).T + params[\"b_r\"])       \n",
    "        ht = relu(np.dot(params[\"W_hh\"], np.multiply(rt, h).T).T + np.dot(params[\"W_hx\"], xt.T).T + params[\"b_h\"])\n",
    "        h = np.multiply(1. - zt, h) + np.multiply(zt, ht)\n",
    "\n",
    "    return h\n",
    "\n",
    "def gru_predict(params, jets):\n",
    "    h = gru_transform(params, jets)\n",
    "\n",
    "    h = relu(np.dot(params[\"W_clf\"][0], h.T).T + params[\"b_clf\"][0])\n",
    "    h = relu(np.dot(params[\"W_clf\"][1], h.T).T + params[\"b_clf\"][1])\n",
    "    h = sigmoid(np.dot(params[\"W_clf\"][2], h.T).T + params[\"b_clf\"][2])\n",
    "\n",
    "    return h.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0\n",
      "step_size = 0.0005\n",
      "    0\t~loss(train)=1.1045\tloss(valid)=1.1608\troc_auc(valid)=0.4586\tbest_roc_auc(valid)=0.4586\n",
      "   25\t~loss(train)=1.0902\tloss(valid)=1.1455\troc_auc(valid)=0.6154\tbest_roc_auc(valid)=0.6154\n",
      "   50\t~loss(train)=1.0562\tloss(valid)=1.1089\troc_auc(valid)=0.8468\tbest_roc_auc(valid)=0.8468\n",
      "   75\t~loss(train)=0.9644\tloss(valid)=1.0101\troc_auc(valid)=0.9046\tbest_roc_auc(valid)=0.9046\n",
      "  100\t~loss(train)=0.7691\tloss(valid)=0.7985\troc_auc(valid)=0.9579\tbest_roc_auc(valid)=0.9579\n",
      "epoch = 1\n",
      "step_size = 0.0005\n",
      "    0\t~loss(train)=0.4704\tloss(valid)=0.4708\troc_auc(valid)=0.9734\tbest_roc_auc(valid)=0.9734\n",
      "   25\t~loss(train)=0.3787\tloss(valid)=0.3661\troc_auc(valid)=0.9784\tbest_roc_auc(valid)=0.9784\n",
      "   50\t~loss(train)=0.3423\tloss(valid)=0.3246\troc_auc(valid)=0.9786\tbest_roc_auc(valid)=0.9786\n",
      "   75\t~loss(train)=0.3114\tloss(valid)=0.2924\troc_auc(valid)=0.9794\tbest_roc_auc(valid)=0.9794\n",
      "  100\t~loss(train)=0.2814\tloss(valid)=0.2622\troc_auc(valid)=0.9795\tbest_roc_auc(valid)=0.9795\n",
      "epoch = 2\n",
      "step_size = 0.0005\n",
      "    0\t~loss(train)=0.2506\tloss(valid)=0.2291\troc_auc(valid)=0.9807\tbest_roc_auc(valid)=0.9807\n",
      "   25\t~loss(train)=0.2348\tloss(valid)=0.2126\troc_auc(valid)=0.9819\tbest_roc_auc(valid)=0.9819\n",
      "   50\t~loss(train)=0.2246\tloss(valid)=0.2000\troc_auc(valid)=0.9820\tbest_roc_auc(valid)=0.9820\n",
      "   75\t~loss(train)=0.2142\tloss(valid)=0.1882\troc_auc(valid)=0.9833\tbest_roc_auc(valid)=0.9833\n",
      "  100\t~loss(train)=0.2041\tloss(valid)=0.1787\troc_auc(valid)=0.9838\tbest_roc_auc(valid)=0.9838\n",
      "epoch = 3\n",
      "step_size = 0.0004\n",
      "    0\t~loss(train)=0.1900\tloss(valid)=0.1654\troc_auc(valid)=0.9865\tbest_roc_auc(valid)=0.9865\n",
      "   25\t~loss(train)=0.1853\tloss(valid)=0.1595\troc_auc(valid)=0.9882\tbest_roc_auc(valid)=0.9882\n",
      "   50\t~loss(train)=0.1891\tloss(valid)=0.1630\troc_auc(valid)=0.9867\tbest_roc_auc(valid)=0.9882\n",
      "   75\t~loss(train)=0.1792\tloss(valid)=0.1517\troc_auc(valid)=0.9887\tbest_roc_auc(valid)=0.9887\n",
      "  100\t~loss(train)=0.1914\tloss(valid)=0.1662\troc_auc(valid)=0.9871\tbest_roc_auc(valid)=0.9887\n",
      "epoch = 4\n",
      "step_size = 0.0004\n",
      "    0\t~loss(train)=0.1725\tloss(valid)=0.1465\troc_auc(valid)=0.9902\tbest_roc_auc(valid)=0.9902\n",
      "   25\t~loss(train)=0.1703\tloss(valid)=0.1441\troc_auc(valid)=0.9909\tbest_roc_auc(valid)=0.9909\n",
      "   50\t~loss(train)=0.1790\tloss(valid)=0.1532\troc_auc(valid)=0.9874\tbest_roc_auc(valid)=0.9909\n",
      "   75\t~loss(train)=0.1681\tloss(valid)=0.1417\troc_auc(valid)=0.9912\tbest_roc_auc(valid)=0.9912\n",
      "  100\t~loss(train)=0.1790\tloss(valid)=0.1533\troc_auc(valid)=0.9894\tbest_roc_auc(valid)=0.9912\n",
      "epoch = 5\n",
      "step_size = 0.0004\n",
      "    0\t~loss(train)=0.1616\tloss(valid)=0.1371\troc_auc(valid)=0.9921\tbest_roc_auc(valid)=0.9921\n",
      "   25\t~loss(train)=0.1605\tloss(valid)=0.1368\troc_auc(valid)=0.9923\tbest_roc_auc(valid)=0.9923\n",
      "   50\t~loss(train)=0.1629\tloss(valid)=0.1366\troc_auc(valid)=0.9914\tbest_roc_auc(valid)=0.9923\n",
      "   75\t~loss(train)=0.1622\tloss(valid)=0.1390\troc_auc(valid)=0.9915\tbest_roc_auc(valid)=0.9923\n",
      "  100\t~loss(train)=0.1711\tloss(valid)=0.1485\troc_auc(valid)=0.9903\tbest_roc_auc(valid)=0.9923\n",
      "epoch = 6\n",
      "step_size = 0.0004\n",
      "    0\t~loss(train)=0.1551\tloss(valid)=0.1307\troc_auc(valid)=0.9925\tbest_roc_auc(valid)=0.9925\n",
      "   25\t~loss(train)=0.1551\tloss(valid)=0.1309\troc_auc(valid)=0.9926\tbest_roc_auc(valid)=0.9926\n",
      "   50\t~loss(train)=0.1594\tloss(valid)=0.1339\troc_auc(valid)=0.9915\tbest_roc_auc(valid)=0.9926\n",
      "   75\t~loss(train)=0.1575\tloss(valid)=0.1346\troc_auc(valid)=0.9922\tbest_roc_auc(valid)=0.9926\n",
      "  100\t~loss(train)=0.1653\tloss(valid)=0.1421\troc_auc(valid)=0.9911\tbest_roc_auc(valid)=0.9926\n",
      "epoch = 7\n",
      "step_size = 0.0003\n",
      "    0\t~loss(train)=0.1511\tloss(valid)=0.1268\troc_auc(valid)=0.9928\tbest_roc_auc(valid)=0.9928\n",
      "   25\t~loss(train)=0.1508\tloss(valid)=0.1272\troc_auc(valid)=0.9924\tbest_roc_auc(valid)=0.9928\n",
      "   50\t~loss(train)=0.1559\tloss(valid)=0.1315\troc_auc(valid)=0.9916\tbest_roc_auc(valid)=0.9928\n",
      "   75\t~loss(train)=0.1534\tloss(valid)=0.1308\troc_auc(valid)=0.9923\tbest_roc_auc(valid)=0.9928\n",
      "  100\t~loss(train)=0.1587\tloss(valid)=0.1357\troc_auc(valid)=0.9917\tbest_roc_auc(valid)=0.9928\n",
      "epoch = 8\n",
      "step_size = 0.0003\n",
      "    0\t~loss(train)=0.1475\tloss(valid)=0.1237\troc_auc(valid)=0.9925\tbest_roc_auc(valid)=0.9928\n",
      "   25\t~loss(train)=0.1475\tloss(valid)=0.1243\troc_auc(valid)=0.9924\tbest_roc_auc(valid)=0.9928\n",
      "   50\t~loss(train)=0.1529\tloss(valid)=0.1292\troc_auc(valid)=0.9917\tbest_roc_auc(valid)=0.9928\n",
      "   75\t~loss(train)=0.1506\tloss(valid)=0.1285\troc_auc(valid)=0.9923\tbest_roc_auc(valid)=0.9928\n",
      "  100\t~loss(train)=0.1530\tloss(valid)=0.1303\troc_auc(valid)=0.9921\tbest_roc_auc(valid)=0.9928\n",
      "epoch = 9\n",
      "step_size = 0.0003\n",
      "    0\t~loss(train)=0.1447\tloss(valid)=0.1214\troc_auc(valid)=0.9926\tbest_roc_auc(valid)=0.9928\n",
      "   25\t~loss(train)=0.1447\tloss(valid)=0.1221\troc_auc(valid)=0.9924\tbest_roc_auc(valid)=0.9928\n",
      "   50\t~loss(train)=0.1503\tloss(valid)=0.1274\troc_auc(valid)=0.9917\tbest_roc_auc(valid)=0.9928\n",
      "   75\t~loss(train)=0.1477\tloss(valid)=0.1260\troc_auc(valid)=0.9923\tbest_roc_auc(valid)=0.9928\n",
      "  100\t~loss(train)=0.1498\tloss(valid)=0.1277\troc_auc(valid)=0.9922\tbest_roc_auc(valid)=0.9928\n",
      "epoch = 10\n",
      "step_size = 0.0003\n",
      "    0\t~loss(train)=0.1423\tloss(valid)=0.1195\troc_auc(valid)=0.9927\tbest_roc_auc(valid)=0.9928\n",
      "   25\t~loss(train)=0.1423\tloss(valid)=0.1201\troc_auc(valid)=0.9924\tbest_roc_auc(valid)=0.9928\n",
      "   50\t~loss(train)=0.1481\tloss(valid)=0.1259\troc_auc(valid)=0.9916\tbest_roc_auc(valid)=0.9928\n",
      "   75\t~loss(train)=0.1451\tloss(valid)=0.1238\troc_auc(valid)=0.9924\tbest_roc_auc(valid)=0.9928\n",
      "  100\t~loss(train)=0.1465\tloss(valid)=0.1250\troc_auc(valid)=0.9923\tbest_roc_auc(valid)=0.9928\n",
      "epoch = 11\n",
      "step_size = 0.0003\n",
      "    0\t~loss(train)=0.1395\tloss(valid)=0.1172\troc_auc(valid)=0.9932\tbest_roc_auc(valid)=0.9932\n",
      "   25\t~loss(train)=0.1397\tloss(valid)=0.1183\troc_auc(valid)=0.9932\tbest_roc_auc(valid)=0.9932\n",
      "   50\t~loss(train)=0.1454\tloss(valid)=0.1238\troc_auc(valid)=0.9918\tbest_roc_auc(valid)=0.9932\n",
      "   75\t~loss(train)=0.1417\tloss(valid)=0.1208\troc_auc(valid)=0.9926\tbest_roc_auc(valid)=0.9932\n",
      "  100\t~loss(train)=0.1433\tloss(valid)=0.1221\troc_auc(valid)=0.9925\tbest_roc_auc(valid)=0.9932\n",
      "epoch = 12\n",
      "step_size = 0.0003\n",
      "    0\t~loss(train)=0.1364\tloss(valid)=0.1154\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9936\n",
      "   25\t~loss(train)=0.1368\tloss(valid)=0.1164\troc_auc(valid)=0.9933\tbest_roc_auc(valid)=0.9936\n",
      "   50\t~loss(train)=0.1426\tloss(valid)=0.1223\troc_auc(valid)=0.9919\tbest_roc_auc(valid)=0.9936\n",
      "   75\t~loss(train)=0.1382\tloss(valid)=0.1180\troc_auc(valid)=0.9929\tbest_roc_auc(valid)=0.9936\n",
      "  100\t~loss(train)=0.1395\tloss(valid)=0.1190\troc_auc(valid)=0.9928\tbest_roc_auc(valid)=0.9936\n",
      "epoch = 13\n",
      "step_size = 0.0003\n",
      "    0\t~loss(train)=0.1344\tloss(valid)=0.1138\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9936\n",
      "   25\t~loss(train)=0.1348\tloss(valid)=0.1150\troc_auc(valid)=0.9933\tbest_roc_auc(valid)=0.9936\n",
      "   50\t~loss(train)=0.1411\tloss(valid)=0.1214\troc_auc(valid)=0.9918\tbest_roc_auc(valid)=0.9936\n",
      "   75\t~loss(train)=0.1360\tloss(valid)=0.1158\troc_auc(valid)=0.9931\tbest_roc_auc(valid)=0.9936\n",
      "  100\t~loss(train)=0.1376\tloss(valid)=0.1174\troc_auc(valid)=0.9929\tbest_roc_auc(valid)=0.9936\n",
      "epoch = 14\n",
      "step_size = 0.0002\n",
      "    0\t~loss(train)=0.1329\tloss(valid)=0.1127\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9937\n",
      "   25\t~loss(train)=0.1332\tloss(valid)=0.1136\troc_auc(valid)=0.9933\tbest_roc_auc(valid)=0.9937\n",
      "   50\t~loss(train)=0.1393\tloss(valid)=0.1201\troc_auc(valid)=0.9918\tbest_roc_auc(valid)=0.9937\n",
      "   75\t~loss(train)=0.1345\tloss(valid)=0.1148\troc_auc(valid)=0.9930\tbest_roc_auc(valid)=0.9937\n",
      "  100\t~loss(train)=0.1353\tloss(valid)=0.1154\troc_auc(valid)=0.9929\tbest_roc_auc(valid)=0.9937\n",
      "epoch = 15\n",
      "step_size = 0.0002\n",
      "    0\t~loss(train)=0.1314\tloss(valid)=0.1119\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9937\n",
      "   25\t~loss(train)=0.1316\tloss(valid)=0.1128\troc_auc(valid)=0.9932\tbest_roc_auc(valid)=0.9937\n",
      "   50\t~loss(train)=0.1378\tloss(valid)=0.1189\troc_auc(valid)=0.9919\tbest_roc_auc(valid)=0.9937\n",
      "   75\t~loss(train)=0.1328\tloss(valid)=0.1135\troc_auc(valid)=0.9930\tbest_roc_auc(valid)=0.9937\n",
      "  100\t~loss(train)=0.1339\tloss(valid)=0.1140\troc_auc(valid)=0.9930\tbest_roc_auc(valid)=0.9937\n",
      "epoch = 16\n",
      "step_size = 0.0002\n",
      "    0\t~loss(train)=0.1301\tloss(valid)=0.1105\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9938\n",
      "   25\t~loss(train)=0.1308\tloss(valid)=0.1117\troc_auc(valid)=0.9933\tbest_roc_auc(valid)=0.9938\n",
      "   50\t~loss(train)=0.1365\tloss(valid)=0.1175\troc_auc(valid)=0.9921\tbest_roc_auc(valid)=0.9938\n",
      "   75\t~loss(train)=0.1316\tloss(valid)=0.1123\troc_auc(valid)=0.9931\tbest_roc_auc(valid)=0.9938\n",
      "  100\t~loss(train)=0.1326\tloss(valid)=0.1133\troc_auc(valid)=0.9930\tbest_roc_auc(valid)=0.9938\n",
      "epoch = 17\n",
      "step_size = 0.0002\n",
      "    0\t~loss(train)=0.1288\tloss(valid)=0.1092\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9938\n",
      "   25\t~loss(train)=0.1295\tloss(valid)=0.1103\troc_auc(valid)=0.9934\tbest_roc_auc(valid)=0.9938\n",
      "   50\t~loss(train)=0.1356\tloss(valid)=0.1165\troc_auc(valid)=0.9922\tbest_roc_auc(valid)=0.9938\n",
      "   75\t~loss(train)=0.1304\tloss(valid)=0.1110\troc_auc(valid)=0.9932\tbest_roc_auc(valid)=0.9938\n",
      "  100\t~loss(train)=0.1308\tloss(valid)=0.1114\troc_auc(valid)=0.9932\tbest_roc_auc(valid)=0.9938\n",
      "epoch = 18\n",
      "step_size = 0.0002\n",
      "    0\t~loss(train)=0.1276\tloss(valid)=0.1083\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9938\n",
      "   25\t~loss(train)=0.1285\tloss(valid)=0.1096\troc_auc(valid)=0.9934\tbest_roc_auc(valid)=0.9938\n",
      "   50\t~loss(train)=0.1344\tloss(valid)=0.1156\troc_auc(valid)=0.9922\tbest_roc_auc(valid)=0.9938\n",
      "   75\t~loss(train)=0.1294\tloss(valid)=0.1102\troc_auc(valid)=0.9931\tbest_roc_auc(valid)=0.9938\n",
      "  100\t~loss(train)=0.1293\tloss(valid)=0.1100\troc_auc(valid)=0.9932\tbest_roc_auc(valid)=0.9938\n",
      "epoch = 19\n",
      "step_size = 0.0002\n",
      "    0\t~loss(train)=0.1265\tloss(valid)=0.1075\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9938\n",
      "   25\t~loss(train)=0.1275\tloss(valid)=0.1088\troc_auc(valid)=0.9933\tbest_roc_auc(valid)=0.9938\n",
      "   50\t~loss(train)=0.1331\tloss(valid)=0.1146\troc_auc(valid)=0.9923\tbest_roc_auc(valid)=0.9938\n",
      "   75\t~loss(train)=0.1281\tloss(valid)=0.1091\troc_auc(valid)=0.9932\tbest_roc_auc(valid)=0.9938\n",
      "  100\t~loss(train)=0.1281\tloss(valid)=0.1090\troc_auc(valid)=0.9932\tbest_roc_auc(valid)=0.9938\n",
      "epoch = 20\n",
      "step_size = 0.0002\n",
      "    0\t~loss(train)=0.1254\tloss(valid)=0.1065\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9938\n",
      "   25\t~loss(train)=0.1267\tloss(valid)=0.1084\troc_auc(valid)=0.9933\tbest_roc_auc(valid)=0.9938\n",
      "   50\t~loss(train)=0.1308\tloss(valid)=0.1121\troc_auc(valid)=0.9927\tbest_roc_auc(valid)=0.9938\n",
      "   75\t~loss(train)=0.1276\tloss(valid)=0.1086\troc_auc(valid)=0.9932\tbest_roc_auc(valid)=0.9938\n",
      "  100\t~loss(train)=0.1269\tloss(valid)=0.1079\troc_auc(valid)=0.9933\tbest_roc_auc(valid)=0.9938\n",
      "epoch = 21\n",
      "step_size = 0.0002\n",
      "    0\t~loss(train)=0.1245\tloss(valid)=0.1046\troc_auc(valid)=0.9940\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1259\tloss(valid)=0.1069\troc_auc(valid)=0.9934\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1297\tloss(valid)=0.1112\troc_auc(valid)=0.9927\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1266\tloss(valid)=0.1077\troc_auc(valid)=0.9932\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1253\tloss(valid)=0.1059\troc_auc(valid)=0.9934\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 22\n",
      "step_size = 0.0002\n",
      "    0\t~loss(train)=0.1237\tloss(valid)=0.1041\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1252\tloss(valid)=0.1060\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1288\tloss(valid)=0.1098\troc_auc(valid)=0.9929\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1257\tloss(valid)=0.1064\troc_auc(valid)=0.9934\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1251\tloss(valid)=0.1058\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 23\n",
      "step_size = 0.0002\n",
      "    0\t~loss(train)=0.1227\tloss(valid)=0.1036\troc_auc(valid)=0.9939\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1242\tloss(valid)=0.1055\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1277\tloss(valid)=0.1091\troc_auc(valid)=0.9930\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1248\tloss(valid)=0.1058\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1241\tloss(valid)=0.1050\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 24\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1219\tloss(valid)=0.1029\troc_auc(valid)=0.9939\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1235\tloss(valid)=0.1050\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1266\tloss(valid)=0.1083\troc_auc(valid)=0.9930\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1240\tloss(valid)=0.1053\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1232\tloss(valid)=0.1042\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 25\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1212\tloss(valid)=0.1026\troc_auc(valid)=0.9939\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1230\tloss(valid)=0.1050\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1256\tloss(valid)=0.1075\troc_auc(valid)=0.9930\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1235\tloss(valid)=0.1047\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1226\tloss(valid)=0.1035\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 26\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1206\tloss(valid)=0.1023\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1223\tloss(valid)=0.1046\troc_auc(valid)=0.9933\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1246\tloss(valid)=0.1069\troc_auc(valid)=0.9929\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1227\tloss(valid)=0.1045\troc_auc(valid)=0.9933\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1217\tloss(valid)=0.1031\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 27\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1199\tloss(valid)=0.1018\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1217\tloss(valid)=0.1043\troc_auc(valid)=0.9934\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1239\tloss(valid)=0.1065\troc_auc(valid)=0.9928\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1221\tloss(valid)=0.1040\troc_auc(valid)=0.9933\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1213\tloss(valid)=0.1025\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 28\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1193\tloss(valid)=0.1013\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1215\tloss(valid)=0.1035\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1233\tloss(valid)=0.1055\troc_auc(valid)=0.9930\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1217\tloss(valid)=0.1034\troc_auc(valid)=0.9934\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1206\tloss(valid)=0.1020\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 29\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1188\tloss(valid)=0.1007\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1206\tloss(valid)=0.1029\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1224\tloss(valid)=0.1052\troc_auc(valid)=0.9930\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1210\tloss(valid)=0.1029\troc_auc(valid)=0.9934\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1200\tloss(valid)=0.1015\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 30\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1186\tloss(valid)=0.1003\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1203\tloss(valid)=0.1024\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1220\tloss(valid)=0.1045\troc_auc(valid)=0.9930\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1206\tloss(valid)=0.1024\troc_auc(valid)=0.9934\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1195\tloss(valid)=0.1010\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 31\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1180\tloss(valid)=0.1002\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1195\tloss(valid)=0.1021\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1213\tloss(valid)=0.1039\troc_auc(valid)=0.9931\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1200\tloss(valid)=0.1019\troc_auc(valid)=0.9934\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1190\tloss(valid)=0.1006\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 32\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1175\tloss(valid)=0.0997\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1190\tloss(valid)=0.1015\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1207\tloss(valid)=0.1035\troc_auc(valid)=0.9931\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1194\tloss(valid)=0.1015\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1185\tloss(valid)=0.1002\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 33\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1171\tloss(valid)=0.0994\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1185\tloss(valid)=0.1012\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1201\tloss(valid)=0.1031\troc_auc(valid)=0.9931\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1188\tloss(valid)=0.1011\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1180\tloss(valid)=0.0998\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 34\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1169\tloss(valid)=0.0987\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1183\tloss(valid)=0.1005\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1197\tloss(valid)=0.1024\troc_auc(valid)=0.9932\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1183\tloss(valid)=0.1004\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1176\tloss(valid)=0.0993\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 35\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1163\tloss(valid)=0.0986\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1176\tloss(valid)=0.1000\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1191\tloss(valid)=0.1020\troc_auc(valid)=0.9932\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1178\tloss(valid)=0.1000\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1171\tloss(valid)=0.0989\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 36\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1160\tloss(valid)=0.0983\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1171\tloss(valid)=0.0996\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1186\tloss(valid)=0.1017\troc_auc(valid)=0.9932\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1174\tloss(valid)=0.0995\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1167\tloss(valid)=0.0986\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 37\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1156\tloss(valid)=0.0980\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1166\tloss(valid)=0.0990\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1183\tloss(valid)=0.1013\troc_auc(valid)=0.9932\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1170\tloss(valid)=0.0992\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1163\tloss(valid)=0.0983\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 38\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1153\tloss(valid)=0.0977\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1161\tloss(valid)=0.0986\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1178\tloss(valid)=0.1009\troc_auc(valid)=0.9933\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1166\tloss(valid)=0.0988\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1159\tloss(valid)=0.0979\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 39\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1150\tloss(valid)=0.0974\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1157\tloss(valid)=0.0980\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1174\tloss(valid)=0.1004\troc_auc(valid)=0.9933\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1162\tloss(valid)=0.0985\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1155\tloss(valid)=0.0976\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 40\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1146\tloss(valid)=0.0971\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1153\tloss(valid)=0.0976\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1170\tloss(valid)=0.1000\troc_auc(valid)=0.9934\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1159\tloss(valid)=0.0981\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1151\tloss(valid)=0.0972\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 41\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1144\tloss(valid)=0.0968\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1149\tloss(valid)=0.0972\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1165\tloss(valid)=0.0995\troc_auc(valid)=0.9934\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1154\tloss(valid)=0.0977\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1148\tloss(valid)=0.0970\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 42\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1140\tloss(valid)=0.0965\troc_auc(valid)=0.9939\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1146\tloss(valid)=0.0971\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1161\tloss(valid)=0.0991\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1150\tloss(valid)=0.0974\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1144\tloss(valid)=0.0966\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 43\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1138\tloss(valid)=0.0963\troc_auc(valid)=0.9939\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1144\tloss(valid)=0.0969\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1158\tloss(valid)=0.0987\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1146\tloss(valid)=0.0970\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1141\tloss(valid)=0.0965\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 44\n",
      "step_size = 0.0001\n",
      "    0\t~loss(train)=0.1135\tloss(valid)=0.0961\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1140\tloss(valid)=0.0966\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1157\tloss(valid)=0.0986\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1143\tloss(valid)=0.0968\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1138\tloss(valid)=0.0963\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 45\n",
      "step_size = 0.0000\n",
      "    0\t~loss(train)=0.1133\tloss(valid)=0.0960\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1137\tloss(valid)=0.0964\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1152\tloss(valid)=0.0980\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1140\tloss(valid)=0.0965\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1135\tloss(valid)=0.0960\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 46\n",
      "step_size = 0.0000\n",
      "    0\t~loss(train)=0.1131\tloss(valid)=0.0958\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1134\tloss(valid)=0.0961\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1150\tloss(valid)=0.0979\troc_auc(valid)=0.9935\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1137\tloss(valid)=0.0964\troc_auc(valid)=0.9937\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1132\tloss(valid)=0.0958\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 47\n",
      "step_size = 0.0000\n",
      "    0\t~loss(train)=0.1129\tloss(valid)=0.0957\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1131\tloss(valid)=0.0959\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1145\tloss(valid)=0.0974\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1133\tloss(valid)=0.0960\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1130\tloss(valid)=0.0956\troc_auc(valid)=0.9939\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 48\n",
      "step_size = 0.0000\n",
      "    0\t~loss(train)=0.1127\tloss(valid)=0.0955\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1129\tloss(valid)=0.0957\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1142\tloss(valid)=0.0971\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1129\tloss(valid)=0.0956\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1128\tloss(valid)=0.0955\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "epoch = 49\n",
      "step_size = 0.0000\n",
      "    0\t~loss(train)=0.1125\tloss(valid)=0.0954\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   25\t~loss(train)=0.1127\tloss(valid)=0.0956\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "   50\t~loss(train)=0.1138\tloss(valid)=0.0968\troc_auc(valid)=0.9936\tbest_roc_auc(valid)=0.9940\n",
      "   75\t~loss(train)=0.1127\tloss(valid)=0.0954\troc_auc(valid)=0.9938\tbest_roc_auc(valid)=0.9940\n",
      "  100\t~loss(train)=0.1125\tloss(valid)=0.0951\troc_auc(valid)=0.9939\tbest_roc_auc(valid)=0.9940\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "import autograd as ag\n",
    "from recnn.recnn import log_loss\n",
    "from recnn.recnn import adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n",
    "                                                      test_size=2000,\n",
    "                                                      random_state=1)\n",
    "\n",
    "init = gru_init\n",
    "predict = gru_predict\n",
    "\n",
    "n_epochs = 50\n",
    "batch_size = 64\n",
    "step_size = 0.0005\n",
    "decay = 0.95\n",
    "\n",
    "trained_params = init(44, 5, random_state=1)\n",
    "n_batches = int(np.ceil(len(X_train) / batch_size))\n",
    "best_score = [-np.inf]  # yuck, but works\n",
    "best_params = [trained_params]\n",
    "\n",
    "def loss(X, y, params):\n",
    "    y_pred = predict(params, X)\n",
    "    l = log_loss(y, y_pred).mean()\n",
    "    return l\n",
    "\n",
    "def objective(params, iteration):\n",
    "    rng = check_random_state(iteration % n_batches)\n",
    "    start = rng.randint(len(X_train) - batch_size)\n",
    "    idx = slice(start, start+batch_size)\n",
    "    return loss(X_train[idx], y_train[idx], params)\n",
    "\n",
    "def callback(params, iteration, gradient):\n",
    "    if iteration % 25 == 0:\n",
    "        roc_auc = roc_auc_score(y_valid, predict(params, X_valid))\n",
    "\n",
    "        if roc_auc > best_score[0]:\n",
    "            best_score[0] = roc_auc\n",
    "            best_params[0] = copy.deepcopy(params)\n",
    "\n",
    "        print(\n",
    "            \"%5d\\t~loss(train)=%.4f\\tloss(valid)=%.4f\"\n",
    "            \"\\troc_auc(valid)=%.4f\\tbest_roc_auc(valid)=%.4f\" % (\n",
    "                iteration,\n",
    "                loss(X_train[:5000], y_train[:5000], params),\n",
    "                loss(X_valid, y_valid, params),\n",
    "                roc_auc,\n",
    "                best_score[0]))\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    print(\"epoch = %d\" % i)\n",
    "    print(\"step_size = %.4f\" % step_size)\n",
    "\n",
    "    trained_params = adam(ag.grad(objective),\n",
    "                          trained_params,\n",
    "                          step_size=step_size,\n",
    "                          num_iters=1 * n_batches,\n",
    "                          callback=callback)\n",
    "    step_size = step_size * decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "267.412839137\n",
      "39.415250207\n",
      "23.5980411797\n",
      "21.2168321198\n",
      "20.7118046871\n",
      "16.7117347687\n",
      "19.1275465395\n",
      "17.9334322172\n",
      "14.2339908259\n",
      "13.613350919\n",
      "13.4888093673\n",
      "11.0020772977\n",
      "12.8344669934\n",
      "9.44970514663\n",
      "7.49511069272\n",
      "6.82304032534\n",
      "4.56652662732\n",
      "4.55178909615\n",
      "4.20511455536\n",
      "3.62597806086\n",
      "2.83713767679\n",
      "2.89979446348\n",
      "2.79273584374\n",
      "2.68638084093\n",
      "2.54697387992\n",
      "2.52295906405\n",
      "2.14501939776\n",
      "1.98560288337\n",
      "1.76643438865\n",
      "1.76915223772\n",
      "1.46660150246\n",
      "1.38870984055\n",
      "1.24643686425\n",
      "0.892840041959\n",
      "0.867205290703\n",
      "0.710562603467\n",
      "0.614620043501\n",
      "0.54687411684\n",
      "0.473092426327\n",
      "0.405385085637\n",
      "0.402666616646\n",
      "0.311493311602\n",
      "0.229915034303\n",
      "0.104200466638\n",
      "0.102050561206\n",
      "0.0564801816809\n",
      "0.0257452279404\n"
     ]
    }
   ],
   "source": [
    "features, jets = events[5]\n",
    "print(y[5])\n",
    "for j in jets:\n",
    "    print(j[\"pt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0.56420626256825046)\n",
      "(1, 0.96776727871069124)\n",
      "(2, 0.83230303329212141)\n",
      "(3, 0.7687326307493052)\n",
      "(4, 0.71567674862706998)\n",
      "(5, 0.66643188665727549)\n",
      "(6, 0.63598322543932906)\n",
      "(7, 0.61117750444710017)\n",
      "(8, 0.59528634381145373)\n",
      "(9, 0.58424578336983135)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i, roc_auc_score(y, [-jets[i][\"pt\"] for _, jets in events]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAHpCAYAAABqV/58AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe9ad538450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([jets[0][\"pt\"] for i, (f, jets) in enumerate(events) if y[i] == 1], histtype=\"step\", bins=30, normed=1, label=\"w\")\n",
    "plt.hist([jets[0][\"pt\"] for i, (f, jets) in enumerate(events) if y[i] == 0], histtype=\"step\", bins=30, normed=1, label=\"qcd\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"pt (1st jet)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
